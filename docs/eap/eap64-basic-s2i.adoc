////
    AUTOGENERATED FILE - this file was generated via ./gen_template_docs.py.
    Changes to .adoc or HTML files may be overwritten! Please change the
    generator or the input template (./*.in)
////

= eap64-basic-s2i
:toc:
:toc-placement!:
:toclevels: 5

Application template for EAP 6 applications built using S2I.

toc::[]


== Parameters

Templates allow you to define parameters which take on a value. That value is then substituted wherever the parameter is referenced.
References can be defined in any text field in the objects list field. Refer to the
https://docs.openshift.org/latest/architecture/core_concepts/templates.html#parameters[Openshift documentation] for more information.

|=======================================================================
|Variable name |Image Environment Variable |Description |Example value |Required

|`APPLICATION_NAME` | -- | The name for the application. | eap-app | True
|`HOSTNAME_HTTP` | -- | Custom hostname for http service route.  Leave blank for default hostname, e.g.: <application-name>-<project>.<default-domain-suffix> | -- | False
|`SOURCE_REPOSITORY_URL` | -- | Git source URI for application | https://github.com/jboss-developer/jboss-eap-quickstarts | True
|`SOURCE_REPOSITORY_REF` | -- | Git branch/tag reference | 6.4.x | False
|`CONTEXT_DIR` | -- | Path within Git project to build; empty for root project directory. | kitchensink | False
|`HORNETQ_QUEUES` | `HORNETQ_QUEUES` | Queue names | `${HORNETQ_QUEUES}` | False
|`HORNETQ_TOPICS` | `HORNETQ_TOPICS` | Topic names | `${HORNETQ_TOPICS}` | False
|`HORNETQ_CLUSTER_PASSWORD` | `HORNETQ_CLUSTER_PASSWORD` | HornetQ cluster admin password | `${HORNETQ_CLUSTER_PASSWORD}` | True
|`GITHUB_WEBHOOK_SECRET` | -- | GitHub trigger secret | secret101 | True
|`GENERIC_WEBHOOK_SECRET` | -- | Generic build trigger secret | secret101 | True
|`IMAGE_STREAM_NAMESPACE` | -- | Namespace in which the ImageStreams for Red Hat Middleware images are installed. These ImageStreams are normally installed in the openshift namespace. You should only need to modify this if you've installed the ImageStreams in a different namespace/project. | openshift | True
|`JGROUPS_CLUSTER_PASSWORD` | `JGROUPS_CLUSTER_PASSWORD` | JGroups cluster password | `${JGROUPS_CLUSTER_PASSWORD}` | True
|`AUTO_DEPLOY_EXPLODED` | `AUTO_DEPLOY_EXPLODED` | Controls whether exploded deployment content should be automatically deployed | false | False
|`MAVEN_MIRROR_URL` | -- | Maven mirror to use for S2I builds | -- | False
|`ARTIFACT_DIR` | -- | List of directories from which archives will be copied into the deployment folder. If unspecified, all archives in /target will be copied. | -- | False
|=======================================================================



== Objects

The CLI supports various object types. A list of these object types as well as their abbreviations
can be found in the https://docs.openshift.org/latest/cli_reference/basic_cli_operations.html#object-types[Openshift documentation].


=== Services

A service is an abstraction which defines a logical set of pods and a policy by which to access them. Refer to the
https://cloud.google.com/container-engine/docs/services/[container-engine documentation] for more information.

|=============
|Service        |Port  |Name | Description

.1+| `${APPLICATION_NAME}`
|8080 | --
.1+| The web server's http port.
|=============



=== Routes

A route is a way to expose a service by giving it an externally-reachable hostname such as `www.example.com`. A defined route and the endpoints
identified by its service can be consumed by a router to provide named connectivity from external clients to your applications. Each route consists
of a route name, service selector, and (optionally) security configuration. Refer to the
https://docs.openshift.com/enterprise/3.0/architecture/core_concepts/routes.html[Openshift documentation] for more information.

|=============
| Service    | Security | Hostname

|`${APPLICATION_NAME}-http` | none | `${HOSTNAME_HTTP}`
|=============



=== Build Configurations

A `buildConfig` describes a single build definition and a set of triggers for when a new build should be created.
A `buildConfig` is a REST object, which can be used in a POST to the API server to create a new instance. Refer to
the https://docs.openshift.com/enterprise/3.0/dev_guide/builds.html#defining-a-buildconfig[Openshift documentation]
for more information.

|=============
| S2I image  | link | Build output | BuildTriggers and Settings

|jboss-eap64-openshift:1.5 |  link:../../eap/eap-openshift{outfilesuffix}[`jboss-eap-6/eap64-openshift`] | `${APPLICATION_NAME}:latest` | GitHub, Generic, ImageChange, ConfigChange
|=============


=== Deployment Configurations

A deployment in OpenShift is a replication controller based on a user defined template called a deployment configuration. Deployments are created manually or in response to triggered events.
Refer to the https://docs.openshift.com/enterprise/3.0/dev_guide/deployments.html#creating-a-deployment-configuration[Openshift documentation] for more information.


==== Triggers

A trigger drives the creation of new deployments in response to events, both inside and outside OpenShift. Refer to the
https://access.redhat.com/beta/documentation/en/openshift-enterprise-30-developer-guide#triggers[Openshift documentation] for more information.

|============
|Deployment | Triggers

|`${APPLICATION_NAME}` | ImageChange
|============



==== Replicas

A replication controller ensures that a specified number of pod "replicas" are running at any one time.
If there are too many, the replication controller kills some pods. If there are too few, it starts more.
Refer to the https://cloud.google.com/container-engine/docs/replicationcontrollers/[container-engine documentation]
for more information.

|============
|Deployment | Replicas

|`${APPLICATION_NAME}` | 1
|============


==== Pod Template




===== Image

|============
|Deployment | Image

|`${APPLICATION_NAME}` | `${APPLICATION_NAME}`
|============



===== Readiness Probe


.${APPLICATION_NAME}
----
/bin/bash -c /opt/eap/bin/readinessProbe.sh
----




===== Exposed Ports

|=============
|Deployments | Name  | Port  | Protocol

.3+| `${APPLICATION_NAME}`
|jolokia | 8778 | `TCP`
|http | 8080 | `TCP`
|ping | 8888 | `TCP`
|=============



===== Image Environment Variables

|=======================================================================
|Deployment |Variable name |Description |Example value

.7+| `${APPLICATION_NAME}`
|`OPENSHIFT_KUBE_PING_LABELS` | -- | `application=${APPLICATION_NAME}`
|`OPENSHIFT_KUBE_PING_NAMESPACE` | -- | --
|`HORNETQ_CLUSTER_PASSWORD` | HornetQ cluster admin password | `${HORNETQ_CLUSTER_PASSWORD}`
|`HORNETQ_QUEUES` | Queue names | `${HORNETQ_QUEUES}`
|`HORNETQ_TOPICS` | Topic names | `${HORNETQ_TOPICS}`
|`JGROUPS_CLUSTER_PASSWORD` | JGroups cluster password | `${JGROUPS_CLUSTER_PASSWORD}`
|`AUTO_DEPLOY_EXPLODED` | Controls whether exploded deployment content should be automatically deployed | `${AUTO_DEPLOY_EXPLODED}`
|=======================================================================




=== External Dependencies






[[clustering]]
==== Clustering

Clustering in OpenShift EAP is achieved through one of two discovery mechanisms:
Kubernetes or DNS. This is done by configuring the JGroups protocol stack in
standalone-openshift.xml with either the `<openshift.KUBE_PING/>` or `<openshift.DNS_PING/>`
elements. Out of the box, `KUBE_PING` is the supported protocol and what is
pre-configured in OpenShift EAP.

For `KUBE_PING` to work, however, the following steps must be taken:

. The `OPENSHIFT_KUBE_PING_NAMESPACE` environment variable must be set (see table above).
  If not set, the server will act as if it is a single-node cluster (a "cluster of one").
. The `OPENSHIFT_KUBE_PING_LABELS` environment variables should be set (see table above).
  If not set, pods outside of your application (albeit in your namespace) will try to join.
. Authorization must be granted to the service account the pod is running under to be
  allowed to access Kubernetes' REST api. This is done on the command line.

.Policy commands
====
Using the default service account in the myproject namespace:
....
oc policy add-role-to-user view system:serviceaccount:myproject:default -n myproject
....
Using the eap-service-account in the myproject namespace:
....
oc policy add-role-to-user view system:serviceaccount:myproject:eap-service-account -n myproject
....
====


